{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43c21e89",
   "metadata": {},
   "source": [
    "# Три этапа конвейера: \n",
    "- предобработку с помощью токенизаторов\n",
    "- прохождение входных данных через модель \n",
    "- постобработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc7c31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предобработка с помощью токенизаторов\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\" # основа для дистиллята, без корпуса, с точной настройкой\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab6b86e",
   "metadata": {},
   "source": [
    "Когда у нас есть токенизатор, мы можем напрямую передать ему наши предложения и получить в ответ словарь, готовый к передаче в нашу модель! Осталось только преобразовать список входных идентификаторов в тензоры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e2046d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': <tf.Tensor: shape=(2, 16), dtype=int32, numpy=\n",
      "array([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662,\n",
      "        12172,  2607,  2026,  2878,  2166,  1012,   102],\n",
      "       [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0]])>, 'attention_mask': <tf.Tensor: shape=(2, 16), dtype=int32, numpy=\n",
      "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])>}\n"
     ]
    }
   ],
   "source": [
    "raw_inputs = [\n",
    "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
    "    \"I hate this so much!\",\n",
    "]\n",
    "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"tf\")\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc767c4",
   "metadata": {},
   "source": [
    "Для нашего примера нам понадобится модель с головой классификации последовательности (чтобы иметь возможность классифицировать предложения как положительные или отрицательные). Поэтому мы будем использовать не класс TFAutoModel, а TFAutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "206e9243",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2)\n",
      "tf.Tensor(\n",
      "[[-1.5606993  1.6122842]\n",
      " [ 4.169231  -3.3464477]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Прохождение входных данных через модель\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
    "outputs = model(inputs)\n",
    "\n",
    "print(outputs.logits.shape)\n",
    "print(outputs.logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "782ab34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[4.0195152e-02 9.5980483e-01]\n",
      " [9.9945587e-01 5.4418418e-04]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "predictions = tf.math.softmax(outputs.logits, axis=-1)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5182f418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'NEGATIVE', 1: 'POSITIVE'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Постобработка\n",
    "model.config.id2label"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds-vl2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
